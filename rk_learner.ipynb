{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed92e4c-4e96-4a06-93c2-5e2cb1bccd3b",
   "metadata": {},
   "source": [
    "## Create your own implementation of Learner from scratch, based on the training loop  show  in this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "065f2642-c8f9-4f66-aa46-4c357533705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131b5c3a-341b-4ce6-9e78-e6ced12f5f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f149c244b70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c69314e-2e39-41e6-b288-9244db17a99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/risheek/.fastai/data/mnist_png/training'),Path('/home/risheek/.fastai/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d650746-551c-4da4-9c06-7edd2501884a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+lVSzBVBJJwAO9dQnw28ZPpM2pnw9ex2kMRmd5VCHYOpCsQx9eB05rlqlt7ea7uYra3ieWeVwkcaDLMxOAAPUmvdNE8HaL8JPDsXi3xcgutcbmysMjEcmOB1wWHUt0XtzWl4C+IvibxPrGqeI9dmis/CmnWrmaKOIeWWOMKCeWbHPX0GOa+dK9W+Ben21x4g1O/2QTapZWu7ToJXC7pWyMgnjIHqD97Par+u6faboL34m+NItTubM/JpWlsskpDMWZWYbQvb8BgHpXFeMvHkviSCDStPtE0zw/Z4+zWMfsMbnP8TdT+PfrXH0UUUV/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABDklEQVR4AWNgGAqAmZ0FuzNZeCs6d/3rY8Qma7L5Hxj4YJE0fQGR+3caU9LsOUju8eon//6hS3LUPwNK3c/nZij89x9NkmMSUOpOPj9QuBBdp/EeoNxHXbCOY2iS7NuAcpfMwHI+P/8tQzbW6DBIXyhYSPL0v4eqSJL8T4Fy/zLAIlKn//1LR5JjmQqS2ywAErI/9e++AzOSpOm/f2cLHweARJy+/bufhiTFYPj6335BBlk+BgaJnY/+bUaRY3D7B3GdcxzQD/fEkfUxMGz5d8yBgcG59tu/fw9LRFDlGM78e5Fd9Rwo9cRMEE2KgaEZ5NZ//zb26WNIMTC4d5z+t62MB0f0MzCzMWHRRCMhAPdAh4q7tpEvAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_path = (path/'training'/'0').ls()[0]\n",
    "example = Image.open(example_path)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc99b0-5eda-4702-93f3-97e332ea6b86",
   "metadata": {},
   "source": [
    "## train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0709fbd2-d997-451c-ad95-8b2262087614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable: 2 and # images:5958\n",
      "lable: 3 and # images:6131\n",
      "lable: 1 and # images:6742\n",
      "lable: 7 and # images:6265\n",
      "lable: 6 and # images:5918\n",
      "lable: 8 and # images:5851\n",
      "lable: 4 and # images:5842\n",
      "lable: 5 and # images:5421\n",
      "lable: 0 and # images:5923\n",
      "lable: 9 and # images:5949\n"
     ]
    }
   ],
   "source": [
    "for gpFolder in path.ls():\n",
    "    if str(gpFolder).split('/')[-1] != 'training':\n",
    "        break\n",
    "    labels = [[] for i in range(10)]\n",
    "    images = [[] for i in range(10)]\n",
    "    #print(images)\n",
    "    for idx, labelFolder in enumerate(gpFolder.ls()):\n",
    "        labels[idx] = torch.stack([tensor(int(str(labelFolder)[-1:])) for i in labelFolder.ls()])\n",
    "        #print(labels)\n",
    "        images[idx] = torch.stack([tensor(Image.open(image)) for image in labelFolder.ls()])\n",
    "        #images = torch.stack([tensor(Image.open(image)) for image in labelFolder.ls()])\n",
    "        print(f'lable: {str(labelFolder)[-1:]} and # images:{len(images[idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f2a21c-11df-461b-a314-e43f249279ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.cat(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb481fc-b393-4ee4-86f8-3d7ae7f5aa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = torch.cat(images).view(-1,28*28)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d56e49-e9b8-4f4d-a5ff-eaf6eab7a0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = images.type(torch.float32)\n",
    "train_y = labels.unsqueeze(1).type(torch.float32)\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41dc7ded-1d7b-469e-a0ba-d9c5f500dafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([2.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a54fe5-1a6f-4ab9-b7d9-71d3e72d367c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f13a5ec5a10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, shuffle=True, batch_size=32)\n",
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7de5eed-5ba8-4f2b-8aea-9b9593d6d1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 784]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = next(iter(dl))\n",
    "X[0].shape, X[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f4774-85ba-4f0b-b00d-6da0b51a7a5a",
   "metadata": {},
   "source": [
    "## valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e08076de-2d52-4e3b-bc59-ef87d960b491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable: 2 and # images:1032\n",
      "lable: 3 and # images:1010\n",
      "lable: 1 and # images:1135\n",
      "lable: 7 and # images:1028\n",
      "lable: 6 and # images:958\n",
      "lable: 8 and # images:974\n",
      "lable: 4 and # images:982\n",
      "lable: 5 and # images:892\n",
      "lable: 0 and # images:980\n",
      "lable: 9 and # images:1009\n"
     ]
    }
   ],
   "source": [
    "for gpFolder in path.ls():\n",
    "    if str(gpFolder).split('/')[-1] != 'training':\n",
    "        labels = [[] for i in range(10)]\n",
    "        images = [[] for i in range(10)]\n",
    "        #print(images)\n",
    "        for idx, labelFolder in enumerate(gpFolder.ls()):\n",
    "            labels[idx] = torch.stack([tensor(int(str(labelFolder)[-1:])) for i in labelFolder.ls()])\n",
    "            #print(labels)\n",
    "            images[idx] = torch.stack([tensor(Image.open(image)) for image in labelFolder.ls()])\n",
    "            #images = torch.stack([tensor(Image.open(image)) for image in labelFolder.ls()])\n",
    "            print(f'lable: {str(labelFolder)[-1:]} and # images:{len(images[idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b635302-fbad-448a-84cc-7c224bd1f64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.cat(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e741ac32-e3b6-4c2c-ad5a-167d0f14eacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 784])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = torch.cat(images).view(-1,28*28)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad32c13d-87d0-4399-811e-cd5fc4a86e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]), torch.Size([10000, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = images.type(torch.float32)\n",
    "valid_y = labels.unsqueeze(1).type(torch.float32)\n",
    "valid_x.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5fca8f3-615f-4be8-9b69-0408e947186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([2.]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(valid_x,valid_y))\n",
    "x,y = dset[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a91a82c0-e21d-4c17-8f57-0f66cf747993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f13a5cba5d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dl = DataLoader(dset, shuffle=True, batch_size=32)\n",
    "valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3aafdc2-6f42-41d8-8528-3f8a2d46743e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 784]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = next(iter(valid_dl))\n",
    "X[0].shape, X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8833d385-2e66-44d1-b705-1bedba3ab423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 313)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iter(dl)), len(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10537901-d235-4121-ada9-098fb02d93de",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69186440-823c-4952-ae86-cb07e3375601",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(28*28,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9d4d157a-c466-4450-b64d-f352bf9430e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layered_model = nn.Sequential(\n",
    "    nn.Linear(28*28,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4e481d8-0f67-4e1f-b25e-f1ee2a5aa98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 784]), torch.Size([10]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = linear_model.parameters()\n",
    "w.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "82252303-eb90-413a-9870-4bfea63e05ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 784]),\n",
       " torch.Size([512]),\n",
       " torch.Size([10, 512]),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1,b1,w2,b2 = layered_model.parameters()\n",
    "w1.shape, b1.shape, w2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "79a76eb7-7014-4b7a-83d4-9cc3b33e3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, epochs, train_dl, valid_dl):\n",
    "    df = pd.DataFrame()\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        accuracy = 0\n",
    "        model.train()\n",
    "        for data in train_dl:\n",
    "            train_x = data[0]\n",
    "            train_y = data[1]\n",
    "            pred = model(train_x)\n",
    "            #print(pred.shape, train_y.shape)\n",
    "            #print(pred)\n",
    "            loss = F.cross_entropy(pred, train_y.squeeze().type(torch.long))\n",
    "            #print(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss/len(train_dl)\n",
    "        #print(train_loss)\n",
    "        #print(\"### END of training loop###\")\n",
    "        model.eval()\n",
    "        for data in valid_dl:\n",
    "            valid_x = data[0]\n",
    "            valid_y = data[1]\n",
    "            pred = model(valid_x)\n",
    "            batch_accuracy = torch.where(torch.argmax(pred,1)==valid_y.T,1,0).sum()/len(valid_y)\n",
    "            accuracy += batch_accuracy\n",
    "            #print(pred.shape, train_y.shape)\n",
    "            #print(pred)\n",
    "            loss = F.cross_entropy(pred, valid_y.squeeze().type(torch.long))\n",
    "            #print(loss.item())\n",
    "            valid_loss += loss.item()\n",
    "        valid_loss = valid_loss/len(valid_dl)\n",
    "        accuracy = accuracy/len(valid_dl)\n",
    "        #print(valid_loss, accuracy)\n",
    "        result = pd.DataFrame.from_dict({\n",
    "            'epoch': [epoch], 'train_loss':[train_loss], 'valid_loss':[valid_loss], 'accuracy':[accuracy]\n",
    "        })\n",
    "        df = pd.concat((df, result), axis=0, ignore_index=True)\n",
    "        clear_output(wait=True)\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6e997bf7-d45c-416c-8c3d-d0af4a1ff98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch    train_loss    valid_loss        accuracy\n",
      "0       0  1.832453e+08  1.725147e+08  tensor(0.8671)\n",
      "1       1  1.829803e+08  1.722721e+08  tensor(0.8671)\n",
      "2       2  1.827165e+08  1.720107e+08  tensor(0.8671)\n",
      "3       3  1.824539e+08  1.719426e+08  tensor(0.8670)\n",
      "4       4  1.821921e+08  1.718883e+08  tensor(0.8674)\n",
      "..    ...           ...           ...             ...\n",
      "95     95  1.617168e+08  1.521648e+08  tensor(0.8753)\n",
      "96     96  1.615225e+08  1.520667e+08  tensor(0.8754)\n",
      "97     97  1.613287e+08  1.527199e+08  tensor(0.8753)\n",
      "98     98  1.611351e+08  1.514056e+08  tensor(0.8758)\n",
      "99     99  1.609418e+08  1.514981e+08  tensor(0.8757)\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.SGD(linear_model.parameters(), lr=0.5)\n",
    "train_model(linear_model, opt, 100, dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9f873514-8fd0-458c-91b2-210a40a9e864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch  train_loss  valid_loss        accuracy\n",
      "0       0    1.807475    1.845339  tensor(0.2922)\n",
      "1       1    1.853814    1.790963  tensor(0.3471)\n",
      "2       2    1.745896    1.713972  tensor(0.3386)\n",
      "3       3    1.782728    1.900687  tensor(0.2763)\n",
      "4       4    1.858573    1.866309  tensor(0.2882)\n",
      "..    ...         ...         ...             ...\n",
      "95     95    1.972376    2.078864  tensor(0.2191)\n",
      "96     96    2.009105    2.082118  tensor(0.2063)\n",
      "97     97    2.037362    2.059248  tensor(0.2034)\n",
      "98     98    2.006358    2.209766  tensor(0.2152)\n",
      "99     99    2.007381    2.143042  tensor(0.1843)\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.SGD(layered_model.parameters(), lr=0.01)\n",
    "train_model(layered_model, opt, 100, dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e19af3-592f-474d-b2af-7f5527c08b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
